{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRSCAtt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudh-chakravarthy/MRSCAtt/blob/main/MRSCAtt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hX_zpKKQQw6"
      },
      "source": [
        "# MRSCAtt: A Spatio-Channel Attention-Guided Network for Mars Rover Image Classification (CVPRW 2021)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xzs6J97eZ5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad553afb-c2df-4230-bcc8-8d12c534974b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMCNVFByve6b"
      },
      "source": [
        "%cd gdrive/MyDrive/MARS_ROVER_IMAGE_CLASSIFICATION/\n",
        "DATA_DIR = 'DATA/msl-images/'\n",
        "CKPT_DIR = 'checkpoints-Roshan/'\n",
        "RESULT_FILE = 'Results-Roshan'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0RkKtO2epH3"
      },
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import OrderedDict\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import DataParallel\n",
        "from torchvision import models, transforms, utils\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "import pdb\n",
        "\n",
        "# Specifications of the dataset. (256x193 images) (25 different categories)\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 193\n",
        "NUM_CATEGORIES = 25\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 20\n",
        "LR = 1e-4\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# seeding for reproducibility\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT_z2hglQisl"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFoRnM6fCbuq"
      },
      "source": [
        "class MarsRoverDataset(Dataset) :\n",
        "    def __init__(self) :\n",
        "        self.root_dir = None\n",
        "        self.transform = None\n",
        "        self.images = None\n",
        "        self.labels = None\n",
        "\n",
        "    def __len__(self) :\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx) :\n",
        "        path = osp.join(self.root_dir, self.images[idx])\n",
        "        sample = {'image': cv2.imread(path), 'class': self.labels[idx]}\n",
        "\n",
        "        if self.transform : \n",
        "            sample[\"image\"] = self.transform(sample[\"image\"])\n",
        "            sample[\"class\"] = torch.tensor(int(sample[\"class\"]), dtype=torch.long)\n",
        "        return sample\n",
        "    \n",
        "    def read_txt(self, split):\n",
        "        dataset = osp.join(DATA_DIR, split + '-calibrated-shuffled.txt')\n",
        "        imgs = []\n",
        "        labels = []\n",
        "\n",
        "        with open(dataset, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                line = line.replace('\\n', '')\n",
        "                line = line.split(' ')\n",
        "                imgs.append(line[0])\n",
        "                labels.append(line[1])\n",
        "\n",
        "        return imgs, labels\n",
        "\n",
        "class trainDataset(MarsRoverDataset) :\n",
        "    def __init__(self, root_dir, transform=None) :\n",
        "        super(trainDataset, self).__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.images, self.labels = self.read_txt('train')\n",
        "        self.transform = transform\n",
        "\n",
        "class validDataset(MarsRoverDataset) :\n",
        "    def __init__(self, root_dir, transform=None) :\n",
        "        super(validDataset, self).__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.images, self.labels = self.read_txt('val')\n",
        "        self.transform = transform\n",
        "\n",
        "class testDataset(MarsRoverDataset) :\n",
        "    def __init__(self, root_dir, transform=None) :\n",
        "        super(testDataset, self).__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.images, self.labels = self.read_txt('test')\n",
        "        self.transform = transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2oSEZUz6rND"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Resize((IMG_HEIGHT, IMG_WIDTH)), \n",
        "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                       transforms.RandomRotation(72)\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Resize((IMG_HEIGHT, IMG_WIDTH)), \n",
        "])\n",
        "\n",
        "train_set = trainDataset(root_dir=DATA_DIR, transform=test_transforms)\n",
        "valid_set = validDataset(root_dir=DATA_DIR, transform=test_transforms)\n",
        "test_set = testDataset(root_dir=DATA_DIR, transform=test_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naWldTHuQrTH"
      },
      "source": [
        "## MRSCAtt network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VXVzzLYmJDm"
      },
      "source": [
        "class ChannelSpatialBlock(nn.Module):\n",
        "  \"\"\"Contains the implementation of Convolutional Block Attention Module (CBAM).\n",
        "     As described in https://arxiv.org/abs/1807.06521.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, in_channels=2048, kernel_size=7, ratio=8):\n",
        "    super(ChannelSpatialBlock, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.ratio = ratio\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    self.avg_fc1 = nn.Linear(in_channels, in_channels // self.ratio)\n",
        "    self.avg_fc2 = nn.Linear(in_channels // self.ratio, in_channels)\n",
        "    self.max_fc1 = nn.Linear(in_channels, in_channels // self.ratio)\n",
        "    self.max_fc2 = nn.Linear(in_channels // self.ratio, in_channels)\n",
        "    self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=3)\n",
        "\n",
        "    self.avg_bn1 = nn.BatchNorm1d(in_channels//self.ratio, affine=True)\n",
        "    self.avg_bn2 = nn.BatchNorm1d(in_channels, affine=True)\n",
        "    self.max_bn1 = nn.BatchNorm1d(in_channels//self.ratio, affine=True)\n",
        "    self.max_bn2 = nn.BatchNorm1d(in_channels, affine=True)\n",
        "    self.bn = nn.BatchNorm2d(1, affine=True)\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "          nn.init.kaiming_normal_(\n",
        "              m.weight, mode='fan_out', nonlinearity='relu')\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "  \n",
        "  def channel_attention(self, x):\n",
        "    avg_pool = torch.mean(x, dim=(-1, -2), keepdim=False) # (N, C)\n",
        "    avg_pool = self.avg_fc1(avg_pool) # (N, C/r)\n",
        "    avg_pool = self.avg_bn1(avg_pool) # (N, C/r)\n",
        "    avg_pool = self.dropout(avg_pool)\n",
        "    avg_pool = self.avg_fc2(avg_pool) # (N, C)\n",
        "    avg_pool = self.avg_bn2(avg_pool) # (N, C)\n",
        "    avg_pool = self.dropout(avg_pool)\n",
        "\n",
        "    max_pool, _ = torch.max(x, dim=-1, keepdim=False) # (N, C, H)\n",
        "    max_pool, _ = torch.max(max_pool, dim=-1, keepdim=False) # (N, C)\n",
        "    max_pool = self.max_fc1(max_pool) # (N, C/r)\n",
        "    max_pool = self.max_bn1(max_pool) # (N, C/r)\n",
        "    max_pool = self.dropout(max_pool)\n",
        "    max_pool = self.max_fc2(max_pool) # (N, C)\n",
        "    max_pool = self.max_bn2(max_pool) # (N, C)\n",
        "    max_pool = self.dropout(max_pool)\n",
        "\n",
        "    scale = F.sigmoid(avg_pool + max_pool)[:, :, None, None] # (N, C, 1, 1)\n",
        "    return scale, x * scale\n",
        "\n",
        "  def spatial_attention(self, x):\n",
        "    avg_pool = torch.mean(x, dim=1, keepdim=True) # (N, 1, H, W)\n",
        "    max_pool, _ = torch.max(x, dim=1, keepdim=True) # (N, 1, H, W)\n",
        "\n",
        "    concat = torch.cat([avg_pool, max_pool], dim=1) # (N, 2, H, W)\n",
        "    concat = self.conv(concat) # (N, 1, H, W)\n",
        "    concat = self.bn(concat)\n",
        "    concat = F.sigmoid(concat) # (N, 1, H, W)\n",
        "\n",
        "    return concat, x * concat\n",
        "\n",
        "  def forward(self, x):\n",
        "    scale, attention_feature = self.channel_attention(x)\n",
        "    concat, attention_feature = self.spatial_attention(attention_feature)\n",
        "    return attention_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAAq9y-GgCn5"
      },
      "source": [
        "class MRSCAtt(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes=25):\n",
        "    super(MRSCAtt, self).__init__()\n",
        "    resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "    self.conv1 = resnet.conv1\n",
        "    self.bn1 = resnet.bn1\n",
        "    self.relu = resnet.relu  # 1/2, 64\n",
        "    self.maxpool = resnet.maxpool\n",
        "    self.avgpool = resnet.avgpool\n",
        "\n",
        "    self.res2 = resnet.layer1 # 1/4, 256\n",
        "    self.res3 = resnet.layer2 # 1/8, 512\n",
        "    self.res4 = resnet.layer3 # 1/16, 1024\n",
        "    self.res5 = resnet.layer4 # 1/32, 2048\n",
        "    self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "    # spatial channel attention block\n",
        "    self.csb = ChannelSpatialBlock(in_channels=2048)\n",
        "\n",
        "    # dropout\n",
        "    # self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    # freeze backbone parameters\n",
        "    for m in [self.conv1, self.bn1, self.res2, self.res3, self.res4]:\n",
        "      for param in m.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    self.register_buffer(\n",
        "        'mean', torch.FloatTensor([0.485, 0.456, 0.406]).view(1,3,1,1))\n",
        "    self.register_buffer(\n",
        "        'std', torch.FloatTensor([0.229, 0.224, 0.225]).view(1,3,1,1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = (x - Variable(self.mean)) / Variable(self.std)\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x) # 1/2, 64\n",
        "    x = self.maxpool(x) # 1/4, 64\n",
        "    r2 = self.res2(x)   # 1/4, 64\n",
        "    r3 = self.res3(r2) # 1/8, 128\n",
        "    r4 = self.res4(r3) # 1/16, 256\n",
        "    r5 = self.res5(r4) # 1/32, 512\n",
        "\n",
        "    r5 = self.csb(r5)\n",
        "\n",
        "    r5 = self.avgpool(r5)\n",
        "    r5 = torch.flatten(r5, 1)\n",
        "    # r5 = self.dropout(r5)\n",
        "    r5 = self.fc(r5)\n",
        "    \n",
        "    return r5, r4, r3, r2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYNMZQlOLjGO"
      },
      "source": [
        "# estimate number of parameters\n",
        "model = MRSCAtt(NUM_CATEGORIES)\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(num_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS30QkRwQ24g"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl6255gs_grM"
      },
      "source": [
        "class RunBuilder():\n",
        "    @staticmethod\n",
        "    def get_runs(params):\n",
        "        Run = namedtuple('Run', params.keys())\n",
        "        runs = []\n",
        "        for v in product(*params.values()):\n",
        "            runs.append(Run(*v))\n",
        "\n",
        "        return runs\n",
        "\n",
        "class RunManager() :\n",
        "    def __init__(self):\n",
        "        self.epoch_count = 0\n",
        "        self.epoch_loss = 0\n",
        "        self.train_epoch_num_correct = 0\n",
        "        self.epoch_start_time = None\n",
        "        self.valid_epoch_loss = 0\n",
        "        self.valid_epoch_num_correct = 0\n",
        "        self.test_epoch_num_correct = 0\n",
        "\n",
        "        self.run_params = None\n",
        "        self.run_count = 0\n",
        "        self.run_data = []\n",
        "        self.run_start_time = None\n",
        "\n",
        "        self.network = None\n",
        "        self.train_loader = None\n",
        "        self.valid_loader = None\n",
        "        self.test_loader = None\n",
        "\n",
        "    def begin_run(self, run, network, train_loader, valid_loader, test_loader, start_epoch=0):\n",
        "        self.run_start_time = time.time()\n",
        "\n",
        "        self.run_params = run\n",
        "        self.run_count += 1\n",
        "\n",
        "        self.network = network\n",
        "        self.train_loader = train_loader\n",
        "        self.valid_loader = valid_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "    def end_run(self):\n",
        "        self.epoch_count = 0\n",
        "    \n",
        "    def begin_epoch(self):\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.epoch_count += 1\n",
        "        self.epoch_loss = 0\n",
        "        self.valid_epoch_loss = 0\n",
        "        self.train_epoch_num_correct = 0\n",
        "        self.valid_epoch_num_correct = 0\n",
        "        self.test_epoch_num_correct = 0\n",
        "        self.network.train()\n",
        "    \n",
        "    def end_epoch(self):\n",
        "        epoch_duration = time.time() - self.epoch_start_time\n",
        "        run_duration = time.time() - self.run_start_time\n",
        "\n",
        "        train_loss = self.epoch_loss / len(self.train_loader.dataset)\n",
        "        valid_loss = self.valid_epoch_loss / len(self.valid_loader.dataset)\n",
        "        train_accuracy = self.train_epoch_num_correct / len(self.train_loader.dataset)\n",
        "        valid_accuracy = self.valid_epoch_num_correct / len(self.valid_loader.dataset)\n",
        "        test_accuracy = self.test_epoch_num_correct / len(self.test_loader.dataset)\n",
        "\n",
        "        results = OrderedDict()\n",
        "        results[\"run\"] = self.run_count\n",
        "        results[\"epoch\"] = self.epoch_count\n",
        "        results['train_loss'] = train_loss\n",
        "        results['valid_loss'] = valid_loss\n",
        "        results[\"train_accuracy\"] = train_accuracy * 100\n",
        "        results[\"valid_accuracy\"] = valid_accuracy * 100\n",
        "        results[\"test_accuracy\"] = test_accuracy * 100\n",
        "        results['epoch_duration'] = epoch_duration\n",
        "        results['run_duration'] = run_duration\n",
        "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "        \n",
        "        self.run_data.append(results)\n",
        "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        display(df)\n",
        "\n",
        "    def track_loss(self, loss):\n",
        "        self.epoch_loss += loss.item()\n",
        "    \n",
        "    def track_valid_loss(self, loss):\n",
        "        self.valid_epoch_loss += loss.item()\n",
        "\n",
        "    def track_num_correct(self, train_preds, train_labels):\n",
        "        self.train_epoch_num_correct += self._get_num_correct(train_preds, train_labels)\n",
        "      \n",
        "    def track_valid_stats(self, valid_preds, valid_labels):\n",
        "        self.valid_epoch_num_correct += self._get_num_correct(valid_preds, valid_labels)\n",
        "\n",
        "    def track_test_stats(self, test_preds, test_labels):\n",
        "        self.test_epoch_num_correct += self._get_num_correct(test_preds, test_labels)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _get_num_correct(self, preds, labels):\n",
        "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "    def saveCheckpoints(self, out_dir, loss) :\n",
        "        if not osp.isdir(out_dir):\n",
        "          os.makedirs(out_dir)\n",
        "        ckpt = osp.join(out_dir, 'epoch_' + str(self.epoch_count) + '.pth')\n",
        "        torch.save({\n",
        "            'epoch': self.epoch_count,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, ckpt)\n",
        "\n",
        "    def save(self, fileName):\n",
        "        pd.DataFrame.from_dict(self.run_data, orient='columns').to_csv(f'{fileName}.csv')\n",
        "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcJab2Ys735R"
      },
      "source": [
        "params = OrderedDict(\n",
        "    lr = [LR],\n",
        "    batch_size = [BATCH_SIZE],\n",
        "    epochs = [NUM_EPOCHS]\n",
        ")\n",
        "\n",
        "m = RunManager()\n",
        "\n",
        "for run in RunBuilder.get_runs(params):\n",
        "    model = MRSCAtt(NUM_CATEGORIES)\n",
        "    model = DataParallel(\n",
        "        model.to(torch.cuda.current_device()), \n",
        "        device_ids=[torch.cuda.current_device()]\n",
        "        )\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), run[0])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=run[1])\n",
        "    valid_loader = DataLoader(valid_set, batch_size=run[1])\n",
        "    test_loader = DataLoader(test_set, batch_size=run[1])\n",
        "    m.begin_run(run, model, train_loader, valid_loader, test_loader)\n",
        "\n",
        "    for epoch in tqdm(range(run[2])):\n",
        "        m.begin_epoch()\n",
        "        for batch in train_loader:\n",
        "            images, labels = batch['image'], batch['class']\n",
        "            train_pred, r4, r3, r2 = model(images.cuda())\n",
        "            train_loss = loss_fn(train_pred, labels.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            m.track_loss(train_loss)\n",
        "            m.track_num_correct(train_pred, labels.cuda())\n",
        "        model.eval()\n",
        "\n",
        "        # validation accuracy stats\n",
        "        for valid_batch in valid_loader:\n",
        "          valid_images, valid_labels = valid_batch['image'], valid_batch['class']\n",
        "          valid_pred, _, _, _ = model(valid_images.cuda())\n",
        "          valid_loss = loss_fn(valid_pred, valid_labels.cuda())\n",
        "\n",
        "          m.track_valid_loss(valid_loss)\n",
        "          m.track_valid_stats(valid_pred, valid_labels.cuda())\n",
        "\n",
        "        # test accuracy stats\n",
        "        for test_batch in test_loader:\n",
        "          test_images, test_labels = test_batch['image'], test_batch['class']\n",
        "          test_pred, _, _, _ = model(test_images.cuda())\n",
        "          m.track_test_stats(test_pred, test_labels.cuda())\n",
        "\n",
        "        m.saveCheckpoints(CKPT_DIR, train_loss)        \n",
        "        m.end_epoch()\n",
        "\n",
        "    m.end_run()\n",
        "m.save('Results-Roshan-R50-SCAtt-loss-curves')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZBTHbkwtqal"
      },
      "source": [
        "train_losses = [0.020033, 0.004966, 0.002251, 0.001156, 0.000543, 0.000284, 0.000173, 0.000131,\n",
        "                0.000062, 0.000043, 0.000035, 0.000029, 0.000025, 0.000021, 0.000019]\n",
        "valid_losses = [0.034559, 0.018036, 0.016703, 0.013259, 0.013580, 0.012898, 0.014908, 0.013318,\n",
        "                0.013530, 0.013288, 0.013193, 0.013178, 0.013189, 0.013137, 0.013228]\n",
        "plt.plot(range(1,len(train_losses)+1), train_losses, label='Training loss')\n",
        "plt.plot(range(1, len(valid_losses)+1), valid_losses, label='Validation loss')\n",
        "plt.xlabel('No. of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQsum1n2RaMf"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTkOPxhFh9O8"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiPvvZ0UZyr3"
      },
      "source": [
        "sota_result_file = \"Results-Roshan-R50-SCAtt-50e-res5freeze-aug-0.2newdropout-newbn.csv\"\n",
        "sota_epoch = \"epoch_13.pth\" # 1-indexed\n",
        "sota_checkpoints_folder = \"checkpoints-Roshan10\"\n",
        "sota_model_path = osp.join(sota_checkpoints_folder, sota_epoch)\n",
        "\n",
        "def track_test_stats(test_preds, test_labels):\n",
        "        return get_num_correct(test_preds, test_labels)\n",
        "\n",
        "def get_num_correct(preds, labels):\n",
        "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "model = MRSCAtt(NUM_CATEGORIES)\n",
        "model = DataParallel(\n",
        "    model.to(torch.cuda.current_device()), \n",
        "    device_ids=[torch.cuda.current_device()]\n",
        "    )\n",
        "model.eval()\n",
        "\n",
        "# loading old state\n",
        "checkpoint = torch.load(sota_model_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# test loader\n",
        "test_set = testDataset(root_dir=DATA_DIR, transform=test_transforms)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "# inference\n",
        "num_correct = 0\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "with torch.no_grad() :\n",
        "    for test_batch in test_loader:\n",
        "        test_images, test_labels = test_batch['image'], test_batch['class']\n",
        "        test_pred, _, _, _ = model(test_images.cuda())    \n",
        "        num_correct += track_test_stats(test_pred, test_labels.cuda())\n",
        "        \n",
        "        predlist=torch.cat([predlist,test_pred.argmax(dim=1).cpu()])\n",
        "        lbllist=torch.cat([lbllist,test_labels.cpu()])\n",
        "\n",
        "# confusion matrix\n",
        "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
        "\n",
        "# accuracy\n",
        "test_accuracy = 100 * num_correct / len(test_loader.dataset)\n",
        "class_accuracy_values = 100*conf_mat.diagonal()/conf_mat.sum(1)\n",
        "class_accuracy = {f'Class {k}':v for k,v in zip(lbllist.unique().numpy(),class_accuracy_values)}\n",
        "print(f\"Class Accuracy: {class_accuracy}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}